{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from IPython.display import Image\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See Image\n",
    "img = Image(\"/home/dhruv/alien_vs_predators/train/alien/5.jpg\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.abspath(\"/home/dhruv/alien_vs_predators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/train/alien/116...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/train/alien/95.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/train/alien/333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/train/alien/334...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/train/alien/182...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train_set\n",
       "0  /home/dhruv/alien_vs_predators/train/alien/116...\n",
       "1  /home/dhruv/alien_vs_predators/train/alien/95.jpg\n",
       "2  /home/dhruv/alien_vs_predators/train/alien/333...\n",
       "3  /home/dhruv/alien_vs_predators/train/alien/334...\n",
       "4  /home/dhruv/alien_vs_predators/train/alien/182..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Set\n",
    "# Alien Images\n",
    "train_alien_images = os.path.join(PATH,\"train\",\"alien\")\n",
    "train_alien = glob(os.path.join(train_alien_images, \"*.jpg\"))\n",
    "# Predators Images\n",
    "train_predator_images = os.path.join(PATH,\"train\",\"predator\")\n",
    "train_predator = glob(os.path.join(train_predator_images,\"*.jpg\"))\n",
    "\n",
    "train = pd.DataFrame()\n",
    "train['train_set'] = train_alien + train_predator\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_set</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/train/alien/116...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/train/alien/95.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/train/alien/333...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/train/alien/334...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/train/alien/182...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           train_set  label\n",
       "0  /home/dhruv/alien_vs_predators/train/alien/116...      1\n",
       "1  /home/dhruv/alien_vs_predators/train/alien/95.jpg      1\n",
       "2  /home/dhruv/alien_vs_predators/train/alien/333...      1\n",
       "3  /home/dhruv/alien_vs_predators/train/alien/334...      1\n",
       "4  /home/dhruv/alien_vs_predators/train/alien/182...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'] = [1 if i in train_alien else 0 for i in train['train_set']] # Labels Aliens = 0, Predators = 1\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(694, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/validation/alie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/validation/alie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/validation/alie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/validation/alie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/validation/alie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             val_set\n",
       "0  /home/dhruv/alien_vs_predators/validation/alie...\n",
       "1  /home/dhruv/alien_vs_predators/validation/alie...\n",
       "2  /home/dhruv/alien_vs_predators/validation/alie...\n",
       "3  /home/dhruv/alien_vs_predators/validation/alie...\n",
       "4  /home/dhruv/alien_vs_predators/validation/alie..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validation Set\n",
    "# Alien\n",
    "val_alien_images = os.path.join(PATH,\"validation\",\"alien\")\n",
    "val_alien = glob(os.path.join(val_alien_images,\"*.jpg\"))\n",
    "# Predator\n",
    "val_predator_images = os.path.join(PATH,\"validation\", \"predator\")\n",
    "val_predator = glob(os.path.join(val_predator_images,\"*.jpg\"))\n",
    "\n",
    "val = pd.DataFrame()\n",
    "val['val_set'] = val_alien + val_predator\n",
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_set</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/validation/alie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/validation/alie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/validation/alie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/validation/alie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/dhruv/alien_vs_predators/validation/alie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             val_set  label\n",
       "0  /home/dhruv/alien_vs_predators/validation/alie...      1\n",
       "1  /home/dhruv/alien_vs_predators/validation/alie...      1\n",
       "2  /home/dhruv/alien_vs_predators/validation/alie...      1\n",
       "3  /home/dhruv/alien_vs_predators/validation/alie...      1\n",
       "4  /home/dhruv/alien_vs_predators/validation/alie...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['label'] = [1 if i in val_alien else 0 for i in val['val_set']] # Labels Aliens = 0, Predators = 1\n",
    "val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 300, 3)\n",
      "251\n"
     ]
    }
   ],
   "source": [
    "# Shapes of images differ!\n",
    "print(cv2.imread(train_alien[1]).shape)\n",
    "print(cv2.imread(train_predator[0]).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv2.imread(train_alien[1]).shape\n",
    "y = cv2.imread(train_predator[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 300, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Select minimum shape value in both train and val set and rescale the images </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = (99999,99999,4)\n",
    "for i in range(0,694):\n",
    "    t = cv2.imread(train.train_set[i]).shape\n",
    "    l = min(l,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 224, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = (99999,99999,4)\n",
    "for i in range(0,200):\n",
    "    x = cv2.imread(val.val_set[i]).shape\n",
    "    k = min(l,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 224, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 694 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating a tf Dataset using flow from directory and rescaling simultaneously\n",
    "# Reference: https://keras.io/api/preprocessing/image\n",
    "# flow_from_directory returns rescaled images in a tf Dataset\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                  '/home/dhruv/alien_vs_predators/train', # train contains 2 classes \"alien\",\"predators\"!\n",
    "                   target_size = (225,224),\n",
    "                   class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating a tf Dataset using flow from directory and rescaling simultaneously\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "                  '/home/dhruv/alien_vs_predators/validation',\n",
    "                   target_size = (225,224),\n",
    "                   class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,Activation,MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 96,kernel_size = (11,11),strides = (4,4),activation = 'relu',input_shape = (225,224,3)))\n",
    "model.add(MaxPool2D(pool_size = (3,3),strides = (2,2)))\n",
    "model.add(Conv2D(filters = 256,kernel_size = (5,5),strides = (1,1)))\n",
    "model.add(MaxPool2D(pool_size = (3,3),strides = (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 22, 22, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                1638464   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,296,513\n",
      "Trainable params: 2,296,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 29s 584ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 34s 677ms/step - loss: 0.6934 - accuracy: 0.4873 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 39s 785ms/step - loss: 0.6934 - accuracy: 0.4880 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 38s 764ms/step - loss: 0.6934 - accuracy: 0.4918 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 42s 833ms/step - loss: 0.6931 - accuracy: 0.5045 - val_loss: 0.6932 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f3490305860>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=50,epochs = 5,validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), input_shape = (225, 224, 3)))\n",
    "model2.add(Activation(\"relu\"))\n",
    "model2.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "model2.add(Conv2D(64, (3, 3), input_shape = (100, 100, 3)))\n",
    "model2.add(Activation(\"relu\"))\n",
    "model2.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(64))\n",
    "model2.add(Activation(\"relu\")) \n",
    "model2.add(Dense(128))\n",
    "model2.add(Activation(\"relu\")) \n",
    "model2.add(Dense(activation = 'sigmoid', units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 223, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 223, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 72, 72, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                2359360   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,387,201\n",
      "Trainable params: 2,387,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 22s 434ms/step - loss: 0.2967 - accuracy: 0.8861 - val_loss: 0.5505 - val_accuracy: 0.6200\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 22s 440ms/step - loss: 0.1617 - accuracy: 0.9414 - val_loss: 0.6530 - val_accuracy: 0.7150\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 24s 473ms/step - loss: 0.0444 - accuracy: 0.9880 - val_loss: 0.6851 - val_accuracy: 0.7100\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 46s 927ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.3988 - val_accuracy: 0.6800\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 31s 624ms/step - loss: 0.0444 - accuracy: 0.9841 - val_loss: 0.6616 - val_accuracy: 0.6750\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 29s 582ms/step - loss: 0.0418 - accuracy: 0.9873 - val_loss: 1.2077 - val_accuracy: 0.6700\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 27s 531ms/step - loss: 0.0044 - accuracy: 0.9994 - val_loss: 0.8387 - val_accuracy: 0.6850\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 30s 601ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.3049 - val_accuracy: 0.6700\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 20s 404ms/step - loss: 8.3754e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.6600\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 21s 428ms/step - loss: 6.3536e-04 - accuracy: 1.0000 - val_loss: 3.3983 - val_accuracy: 0.6750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f349008f7f0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_generator,steps_per_epoch=50,epochs = 10,validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Add Dropuout Regularization for preventing Overfitting </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), input_shape = (225, 224, 3)))\n",
    "model2.add(Activation(\"relu\"))\n",
    "model2.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "model2.add(Conv2D(64, (3, 3), input_shape = (100, 100, 3)))\n",
    "model2.add(Activation(\"relu\"))\n",
    "model2.add(MaxPooling2D(pool_size = (3, 3)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "\n",
    "model2.add(Dense(64))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Activation(\"relu\")) \n",
    "model2.add(Dense(128))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Activation(\"relu\")) \n",
    "model2.add(Dense(activation = 'sigmoid', units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 27s 539ms/step - loss: 0.7151 - accuracy: 0.5380 - val_loss: 0.7475 - val_accuracy: 0.5300\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 27s 534ms/step - loss: 0.6077 - accuracy: 0.7057 - val_loss: 0.4383 - val_accuracy: 0.6250\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 28s 554ms/step - loss: 0.4892 - accuracy: 0.7924 - val_loss: 0.4762 - val_accuracy: 0.6950\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 21s 429ms/step - loss: 0.3089 - accuracy: 0.8930 - val_loss: 0.4589 - val_accuracy: 0.7300\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 24s 472ms/step - loss: 0.1513 - accuracy: 0.9475 - val_loss: 0.8054 - val_accuracy: 0.7400\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 28s 557ms/step - loss: 0.0702 - accuracy: 0.9758 - val_loss: 0.3053 - val_accuracy: 0.7300\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 27s 546ms/step - loss: 0.0561 - accuracy: 0.9842 - val_loss: 0.3136 - val_accuracy: 0.7250\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 27s 542ms/step - loss: 0.0493 - accuracy: 0.9886 - val_loss: 1.1965 - val_accuracy: 0.7100\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 27s 535ms/step - loss: 0.0345 - accuracy: 0.9899 - val_loss: 2.6175 - val_accuracy: 0.7100\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 24s 475ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 1.5406 - val_accuracy: 0.7100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f34a10daf98>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(train_generator,steps_per_epoch=50,epochs = 10,validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 64,kernel_size = (11,11),strides = (4,4),activation = 'relu',input_shape = (225,224,3)))\n",
    "model.add(MaxPool2D(pool_size = (3,3),strides = (2,2)))\n",
    "model.add(Conv2D(filters = 128,kernel_size = (5,5),strides = (1,1)))\n",
    "model.add(MaxPool2D(pool_size = (3,3),strides = (2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 17s 338ms/step - loss: 0.7046 - accuracy: 0.5101 - val_loss: 0.6686 - val_accuracy: 0.6200\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 22s 433ms/step - loss: 0.6380 - accuracy: 0.6551 - val_loss: 0.4850 - val_accuracy: 0.7100\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 21s 428ms/step - loss: 0.5903 - accuracy: 0.7096 - val_loss: 0.9125 - val_accuracy: 0.6050\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 22s 437ms/step - loss: 0.6046 - accuracy: 0.6987 - val_loss: 0.5005 - val_accuracy: 0.7300\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 22s 431ms/step - loss: 0.5416 - accuracy: 0.7392 - val_loss: 0.6378 - val_accuracy: 0.7050\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 21s 410ms/step - loss: 0.5290 - accuracy: 0.7503 - val_loss: 0.4693 - val_accuracy: 0.7050\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 22s 434ms/step - loss: 0.4892 - accuracy: 0.7722 - val_loss: 0.4604 - val_accuracy: 0.7250\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 22s 432ms/step - loss: 0.5118 - accuracy: 0.7682 - val_loss: 0.6056 - val_accuracy: 0.7050\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 23s 453ms/step - loss: 0.4653 - accuracy: 0.7962 - val_loss: 0.2906 - val_accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 22s 443ms/step - loss: 0.4083 - accuracy: 0.8210 - val_loss: 0.3901 - val_accuracy: 0.7450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f3443f35f60>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,steps_per_epoch=50,epochs = 10,validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To further prevent overfitting we require more data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
